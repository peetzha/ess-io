<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Markerless Inside-Out Tool Tracking for Endoscopic Spine Surgery: A Benchmarking Study and Clinical Dataset">
  <meta name="keywords" content="tool tracking, SLAM, Surgical navigation, endoscopy, camera pose estimation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Markerless Inside-Out Tool Tracking for Endoscopic Spine Surgery: A Benchmarking Study and Clinical Dataset</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/icon_endo.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Markerless Inside-Out Tool Tracking for Endoscopic Spine Surgery: A Benchmarking Study and Clinical Dataset</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Peter Zhang<sup>1,2</sup>,</span>
            <span class="author-block">
              Youyang Shen<sup>3</sup>,</span>
            <span class="author-block">
              Frédéric Giraud<sup>2</sup>,
            </span>
            <span class="author-block">
              Nicola A. Cavalcanti<sup>2</sup>,
            </span>
            <span class="author-block">
              Marc Pollefeys<sup>1,4</sup>,
            </span>
            <span class="author-block">
              Christoph J. Laux<sup>5</sup>,
            </span>
            <span class="author-block">
              Philipp Fürnstahl<sup>2,3</sup>
            </span>
            <span class="author-block">
              Hooman Esfandiari<sup>3</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Computer Vision and Geometry Group, ETH Zurich, Zurich, Switzerland,</span>
            <span class="author-block"><sup>2</sup>Research in Orthopedic Computer Science, Balgrist University Hospital, University of Zurich, Zurich, Switzerland,</span>
            <span class="author-block"><sup>3</sup>X23D AG, Zurich, Switzerland,</span>
            <span class="author-block"><sup>4</sup>Spatial AI Lab, Microsoft, Zurich, Switzerland,</span>
            <span class="author-block"><sup>5</sup>Balgrist University Hospital, University of Zurich, Zurich, Switzerland,</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div>
</section> -->
<section class="hero teaser">
    <div class="container is-max-desktop is-centered">
      <div class="hero-body is-centered">
        
        <div class="columns is-centered">
          <div class="column">
            <div class="content">
              <img src="./static/images/tools_annotated.png"
               alt="tools_annotated"/>
            </div>
          </div>
          <div class="column">
            <div class="content">
              <img src="./static/images/ORX.jpg"
               alt="orx_setup"/>
            </div>
          </div>
          <div class="column">
            <div class="content">
              <img src="./static/images/endoscopy_surgery.png"
               alt="data_collection_during_surgery"/>
            </div>
          </div>
        </div>
        
        <div class="content has-text-centered">
          <video id="teaser" autoplay muted playsinline width="75%">
          <source src="./static/videos/sample_right1.mp4"
                  type="video/mp4">
          </video>
        </div>

        <h2 class="subtitle has-text-centered">
            <p>An endoscopic spine surgery dataset with mm-accurate tool poses, tool-mounted stereo cameras, and endoscopic video.</p>
        </h2>
      </div>
    </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            <b>Purpose:</b> Markerless inside-out surgical instrument tracking using a tool-
            mounted camera offers a promising solution to the limited clinical adoption of the
            existing navigation systems, which primarily rely on outside-in optical tracking
            and are constrained by line-of-sight issues. However, its performance in the surgical
            environment, with its unique challenges, remains largely unexplored. This
            work benchmarks state-of-the-art inside-out methods, namely, visual Simultaneous
            Localization and Mapping (vSLAM) methods. To this end, we collected a
            first-of-its-kind dataset in spine endoscopy, providing ground-truth tool poses.
          </p>
          <p>
            <b>Methods:</b> We recorded endoscopic spine surgeries performed on a high-fidelity
            training model in a real operating room environment, containing synchronized stereo images
            from tool-mounted cameras, sub-millimetric ground truth pose data from a commercial optical
            tracking system, and the endoscopic feed. Using this dataset, the instrument tracking accuracy
            of a selected number of vSLAM algorithms was compared.
          </p>
          <p>
            <b>Results:</b> The best performing approach achieved a root mean squared absolute
            trajectory error of 2.0 mm and 1.47 degrees, reaching accuracies of around 1 mm
            and 1 degree on selected sequences. However, it shows degraded performance in
            the presence of challenges such as occlusions and scene-object dynamics.
          </p>
          <p>
            <b>Conclusion:</b> Markerless inside-out tracking using vSLAM demonstrated high
            accuracy, indicating potential feasibility for navigated endoscopic spine applications.
            Our evaluation revealed that current algorithms remain insufficiently
            robust for routine clinical use. The presented study and dataset establish a
            foundation for future research toward reliable, real-time inside-out navigation in
            minimally invasive surgery.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Dataset -->
    <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
            <h2 class="title is-3">Dataset</h2>
            <p><i>This project page is still under construction and the ESS-IO dataset is not yet publically available.</i></p>
            <p><i>A link to a github repo containing download scripts and further details to the dataset format will added here.</i></p>
        </div>
    </div>
    <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
            <img src="./static/images/dataset_overview.png"
                 alt="Dataset overview"/>
            <p>Overview of the available sequences from our ESS-IO dataset. The start of each sequence can be seen below.</p>
        </div>
    </div>
    <div class="column">
      <h3 class="title is-4">Sequence Previews</h3>
      <details class="dropdown-section">
        <summary class="dropdown-title">
          Left1Dil
        </summary>
        <div class="dropdown-content">        
          <video controls autoplay muted playsinline width="100%">
            <source src="./static/videos/Left1Dil_stacked.mp4" type="video/mp4">
          </video>
        </div>
      </details>
      <details class="dropdown-section">
        <summary class="dropdown-title">
          Left1End
        </summary>
        <div class="dropdown-content">        
          <video controls autoplay muted playsinline width="100%">
            <source src="./static/videos/Left1End_stacked.mp4" type="video/mp4">
          </video>
        </div>
      </details>
      <details class="dropdown-section">
        <summary class="dropdown-title">
          Right1Dil
        </summary>
        <div class="dropdown-content">        
          <video controls autoplay muted playsinline width="100%">
            <source src="./static/videos/Right1Dil_stacked.mp4" type="video/mp4">
          </video>
        </div>
      </details>
      <details class="dropdown-section">
        <summary class="dropdown-title">
          Right1End
        </summary>
        <div class="dropdown-content">        
          <video controls autoplay muted playsinline width="100%">
            <source src="./static/videos/Right1End_stacked.mp4" type="video/mp4">
          </video>
        </div>
      </details>
      <details class="dropdown-section">
        <summary class="dropdown-title">
          Left2Dil
        </summary>
        <div class="dropdown-content">        
          <video controls autoplay muted playsinline width="100%">
            <source src="./static/videos/Left2Dil_stacked.mp4" type="video/mp4">
          </video>
        </div>
      </details>
      <details class="dropdown-section">
        <summary class="dropdown-title">
          Left2End
        </summary>
        <div class="dropdown-content">        
          <video controls autoplay muted playsinline width="100%">
            <source src="./static/videos/Left2End_stacked.mp4" type="video/mp4">
          </video>
        </div>
      </details>
      <details class="dropdown-section">
        <summary class="dropdown-title">
          Right2Dil
        </summary>
        <div class="dropdown-content">        
          <video controls autoplay muted playsinline width="100%">
            <source src="./static/videos/Right2Dil_stacked.mp4" type="video/mp4">
          </video>
        </div>
      </details>
      <details class="dropdown-section">
        <summary class="dropdown-title">
          Right2End
        </summary>
        <div class="dropdown-content">        
          <video controls autoplay muted playsinline width="100%">
            <source src="./static/videos/Right2End_stacked.mp4" type="video/mp4">
          </video>
        </div>
      </details>
    </div>

    <div class="column">
      <h3 class="title is-4">CT</h3>

      <details class="dropdown-section">
        <summary class="dropdown-title">
          CT Preview
        </summary>

        <div class="dropdown-content">
          <div class="columns is-centered">
            <div class="columns is-vcentered interpolation-panel">
              <div class="column interpolation-video-column">
                <div id="interpolation-image-wrapper">
                  Loading...
                </div>
                <input class="slider is-fullwidth is-large is-info"
                       id="interpolation-slider"
                       step="1" min="0" max="100" value="0" type="range">
              </div>
            </div>
          </div>
        </div>
       
      </details>
    </div>

    <div class="column">
      <h3 class="title is-4">Calibration</h3>

      <details class="dropdown-section">
        <summary class="dropdown-title">
          Camera Calibration
        </summary>
        <div class="dropdown-content">
          <div class="content has-text-justified">
            <p>
              The calibration files of the stereo cameras are available for download through the mentioned github repo.
              Additionally, we provide additional recordings of a checkerboard, that can be used to compare custom calibration methods.
            </p> 
          </div>        
          <div class="columns is-centered">
            <div class="column">
              <div class="content">
                <img src="./static/images/1767876291306938624_left.png"
               alt="stereo_left_sample"/>
              </div>
            </div>
            <div class="column">
              <div class="content">
                <img src="./static/images/1767876291306938624_right.png"
               alt="stereo_right_sample"/>
              </div>
            </div>
          </div>        
        </div>
      </details>

      <details class="dropdown-section">
        <summary class="dropdown-title">
          Endoscope Calibration
        </summary>
        <div class="dropdown-content">
          <div class="content has-text-justified">
            <p>
              The endoscope calibration files and the code described in the supplementary material is available within the linked repo.
              Note that the calibration is dynamic, dependent on the scope angle. 
            </p> 
          </div>
          <div class="columns is-centered">
            <div class="column">
              <div class="content">
                <video controls autoplay muted playsinline width="100%">
                  <source src="./static/videos/notch.mp4" type="video/mp4">
                </video>
              </div>
            </div>
            <div class="column">
              <div class="content">
                <video controls autoplay muted playsinline width="100%">
                  <source src="./static/videos/endo_cal_sequence.mp4" type="video/mp4">
                </video>
              </div>
            </div>
          </div>        
        </div>
      </details>
    </div>
    <!--/ Dataset -->
  </div>
</section>


<!-- <section class="section">
  <div class="container is-max-desktop"> -->

    <!-- Animation. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Calibration</h2> -->

        <!-- Interpolating. -->
        <!-- <h3 class="title is-4">Interpolating states</h3>
        <div class="content has-text-justified">
          <p>
            We can also animate the scene by interpolating the deformation latent codes of two input
            frames. Use the slider here to linearly interpolate between the left frame and the right
            frame.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_start.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_end.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div>
        <br/> -->
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        <!-- <h3 class="title is-4">Re-rendering the input video</h3>
        <div class="content has-text-justified">
          <p>
            Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
            viewpoint such as a stabilized camera by playing back the training deformations.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/replay.mp4"
                    type="video/mp4">
          </video>
        </div> -->
        <!--/ Re-rendering. -->

      <!-- </div>
    </div> -->
    <!--/ Animation. -->

  <!-- </div>
</section> -->


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <p>Will be made available as soon as possible.</p>
    <!-- <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre> -->
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This website was designed using the template provided by the <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> authors.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
